{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGa0_oLb61zz"
   },
   "source": [
    "# Tutorial 2\n",
    "In this tutorial we're going to take the model we developed in the previous tutorial, run it on the entire MNIST testing set and calculate the overall classification accuracy.\n",
    "\n",
    "## Install PyGeNN wheel from Google Drive\n",
    "Download wheel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14226,
     "status": "ok",
     "timestamp": 1651245375828,
     "user": {
      "displayName": "Jamie Knight",
      "userId": "17931559686369144807"
     },
     "user_tz": -60
    },
    "id": "t2ihZLXh5VD-",
    "outputId": "696d4dc8-ce5a-4181-dbf0-5a8bda182539"
   },
   "outputs": [],
   "source": [
    "!gdown 1-4H8-H48tEnb-9I9EtLyNfPdLQLe2JRV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4oxLk_xy67Pd"
   },
   "source": [
    "and then install PyGeNN from wheel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2692,
     "status": "ok",
     "timestamp": 1651245378514,
     "user": {
      "displayName": "Jamie Knight",
      "userId": "17931559686369144807"
     },
     "user_tz": -60
    },
    "id": "v7Hg9SPK5bZO",
    "outputId": "781eab21-e21f-43dd-bf14-3621297a3e8e"
   },
   "outputs": [],
   "source": [
    "!pip install pygenn-4.8.0-cp38-cp38-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAm5bzGvAb17"
   },
   "source": [
    "Set environment variable to allow GeNN to find CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1651245378515,
     "user": {
      "displayName": "Jamie Knight",
      "userId": "17931559686369144807"
     },
     "user_tz": -60
    },
    "id": "cIzSgI5Q8Wvq",
    "outputId": "7d4c0129-98ff-4906-8011-3f5e567c5aaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_PATH=/usr/local/cuda\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_PATH=/usr/local/cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tqbF5GldF0o"
   },
   "source": [
    "## Download pre-trained weights and MNIST test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23296,
     "status": "ok",
     "timestamp": 1651245401807,
     "user": {
      "displayName": "Jamie Knight",
      "userId": "17931559686369144807"
     },
     "user_tz": -60
    },
    "id": "N-2PV7LcdFg_",
    "outputId": "59119505-75c4-4c5a-87cc-8b7dea309ef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1cmNL8W0QZZtn3dPHiOQnVjGAYTk6Rhpc\n",
      "To: /content/weights_0_1.npy\n",
      "100% 402k/402k [00:00<00:00, 108MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=131lCXLEH6aTXnBZ9Nh4eJLSy5DQ6LKSF\n",
      "To: /content/weights_1_2.npy\n",
      "100% 5.25k/5.25k [00:00<00:00, 6.37MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=14nSMTTlFebhqkudWVpuWnNFFEQx_7lFg\n",
      "To: /content/testing_images.npy\n",
      "100% 7.84M/7.84M [00:00<00:00, 31.7MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1KSLTNx--oNoV1lEGPmo0FQbUlgsmaBKS\n",
      "To: /content/testing_labels.npy\n",
      "100% 10.1k/10.1k [00:00<00:00, 15.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown 1cmNL8W0QZZtn3dPHiOQnVjGAYTk6Rhpc\n",
    "!gdown 131lCXLEH6aTXnBZ9Nh4eJLSy5DQ6LKSF\n",
    "!gdown 14nSMTTlFebhqkudWVpuWnNFFEQx_7lFg\n",
    "!gdown 1KSLTNx--oNoV1lEGPmo0FQbUlgsmaBKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7UOIOeX1xeE"
   },
   "source": [
    "## Build model\n",
    "As well as the standard modules and required PyGeNN functions and classes we used in the first tutorial, also import `time.perf_counter` for measuring the performance of our classifier and `tqdm.tqdm` for drawing progress bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agqWFZjickfU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pygenn.genn_model import (create_custom_neuron_class,\n",
    "                               create_custom_current_source_class,\n",
    "                               GeNNModel)\n",
    "from time import perf_counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMBcXoyd4yS1"
   },
   "source": [
    "As before, define some simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqBx7iO_kApE"
   },
   "outputs": [],
   "source": [
    "TIMESTEP = 1.0\n",
    "PRESENT_TIMESTEPS = 100\n",
    "INPUT_CURRENT_SCALE = 1.0 / 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QlVBYQG431K"
   },
   "source": [
    "Create very similar neuron and current source models. However, to avoid having to download every spike and count them on the CPU, here, we add an additional state variable `SpikeCount` to each neuron which gets incremented in the reset code to count spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7lzXzmQcgbt"
   },
   "outputs": [],
   "source": [
    "# Very simple integrate-and-fire neuron model\n",
    "if_model = create_custom_neuron_class(\n",
    "    \"if_model\",\n",
    "    param_names=[\"Vthr\"],\n",
    "    var_name_types=[(\"V\", \"scalar\"), (\"SpikeCount\", \"unsigned int\")],\n",
    "    sim_code=\"$(V) += $(Isyn) * DT;\",\n",
    "    reset_code=\"\"\"\n",
    "    $(V) = 0.0;\n",
    "    $(SpikeCount)++;\n",
    "    \"\"\",\n",
    "    threshold_condition_code=\"$(V) >= $(Vthr)\")\n",
    "\n",
    "cs_model = create_custom_current_source_class(\n",
    "    \"cs_model\",\n",
    "    var_name_types=[(\"magnitude\", \"scalar\")],\n",
    "    injection_code=\"$(injectCurrent, $(magnitude));\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWMtozHB3OrM"
   },
   "source": [
    "Build model, load weights and create neuron, synapse and current source populations as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sx1VOU5udixG"
   },
   "outputs": [],
   "source": [
    "model = GeNNModel(\"float\", \"tutorial_2\")\n",
    "model.dT = TIMESTEP\n",
    "\n",
    "# Load weights\n",
    "weights_0_1 = np.load(\"weights_0_1.npy\")\n",
    "weights_1_2 = np.load(\"weights_1_2.npy\")\n",
    "\n",
    "if_params = {\"Vthr\": 5.0}\n",
    "if_init = {\"V\": 0.0, \"SpikeCount\":0}\n",
    "neurons = [model.add_neuron_population(\"neuron0\", weights_0_1.shape[0],\n",
    "                                       if_model, if_params, if_init),\n",
    "           model.add_neuron_population(\"neuron1\", weights_0_1.shape[1],\n",
    "                                       if_model, if_params, if_init),\n",
    "           model.add_neuron_population(\"neuron2\", weights_1_2.shape[1],\n",
    "                                       if_model, if_params, if_init)]\n",
    "model.add_synapse_population(\n",
    "        \"synapse_0_1\", \"DENSE_INDIVIDUALG\", 0,\n",
    "        neurons[0], neurons[1],\n",
    "        \"StaticPulse\", {}, {\"g\": weights_0_1.flatten()}, {}, {},\n",
    "        \"DeltaCurr\", {}, {})\n",
    "model.add_synapse_population(\n",
    "        \"synapse_1_2\", \"DENSE_INDIVIDUALG\", 0,\n",
    "        neurons[1], neurons[2],\n",
    "        \"StaticPulse\", {}, {\"g\": weights_1_2.flatten()}, {}, {},\n",
    "        \"DeltaCurr\", {}, {});\n",
    "\n",
    "current_input = model.add_current_source(\"current_input\", cs_model,\n",
    "                                         neurons[0], {}, {\"magnitude\": 0.0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdggjUe13tT_"
   },
   "source": [
    "Run code generator to generate simulation code for model and load it into PyGeNN as before but, here, we don't want to record any spikes so no need to specify a recording buffer size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K8kHbKMJ3kIY"
   },
   "outputs": [],
   "source": [
    "model.build()\n",
    "model.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMxrFcIP66CX"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUxwsE323l37"
   },
   "source": [
    "Just like in the previous tutorial, load testing images and labels and verify their dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Tf07KUOeP-X"
   },
   "outputs": [],
   "source": [
    "testing_images = np.load(\"testing_images.npy\")\n",
    "testing_labels = np.load(\"testing_labels.npy\")\n",
    "\n",
    "assert testing_images.shape[1] == weights_0_1.shape[0]\n",
    "assert np.max(testing_labels) == (weights_1_2.shape[1] - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-TFULk_3i8z"
   },
   "source": [
    "## Simulate model\n",
    "In this tutorial we're going to not only inject current but also access the new spike count variable in the output population and reset the voltages throughout the model. Therefore we need to create some additional memory views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3z1ccKHeejeB"
   },
   "outputs": [],
   "source": [
    "current_input_magnitude = current_input.vars[\"magnitude\"].view\n",
    "output_spike_count = neurons[-1].vars[\"SpikeCount\"].view\n",
    "neuron_voltages = [n.vars[\"V\"].view for n in neurons]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCDP_sTa4HTL"
   },
   "source": [
    "Now, we define our inference loop. We loop through all of the testing images and for each one:\n",
    "\n",
    "1.   Copy the (scaled) image data into the current input memory view and copy it to the GPU\n",
    "2.   Loop through all the neuron populations, zero their membrance voltages and copy these to the GPU\n",
    "3. Zero the output spike count and copy that to the GPU\n",
    "4. Simulate the model for `PRESENT_TIMESTEPS`\n",
    "5. Download the spike counts from the output layer\n",
    "6. If highest spike count corresponds to correct label, increment `num_correct`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29131,
     "status": "ok",
     "timestamp": 1651245455389,
     "user": {
      "displayName": "Jamie Knight",
      "userId": "17931559686369144807"
     },
     "user_tz": -60
    },
    "id": "4qSoinT4etKq",
    "outputId": "3b2ded1b-ad08-43ea-cfb9-4449f3f35ee4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:28<00:00, 345.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy 97.44%%\n",
      "Time 28.963735203000027 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Simulate\n",
    "num_correct = 0\n",
    "start_time = perf_counter()\n",
    "for i in tqdm(range(testing_images.shape[0])):\n",
    "    current_input_magnitude[:] = testing_images[i] * INPUT_CURRENT_SCALE\n",
    "    current_input.push_var_to_device(\"magnitude\")\n",
    "\n",
    "    # Loop through all layers and their corresponding voltage views\n",
    "    for l, v in zip(neurons, neuron_voltages):\n",
    "        # Manually 'reset' voltage\n",
    "        v[:] = 0.0\n",
    "\n",
    "        # Upload\n",
    "        l.push_var_to_device(\"V\")\n",
    "\n",
    "    # Zero spike count\n",
    "    output_spike_count[:] = 0\n",
    "    neurons[-1].push_var_to_device(\"SpikeCount\")\n",
    "\n",
    "    for t in range(PRESENT_TIMESTEPS):\n",
    "        model.step_time()\n",
    "\n",
    "    # Download spike count from last layer\n",
    "    neurons[-1].pull_var_from_device(\"SpikeCount\")\n",
    "\n",
    "    # Find which neuron spiked the most to get prediction\n",
    "    predicted_label = np.argmax(output_spike_count)\n",
    "    true_label = testing_labels[i]\n",
    "\n",
    "    if predicted_label == true_label:\n",
    "        num_correct += 1\n",
    "\n",
    "end_time = perf_counter()\n",
    "print(f\"\\nAccuracy {((num_correct / float(testing_images.shape[0])) * 100.0)}%%\")\n",
    "print(f\"Time {end_time - start_time} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOKKaAS0XCXbwt638nHakBi",
   "collapsed_sections": [],
   "name": "tutorial_2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
