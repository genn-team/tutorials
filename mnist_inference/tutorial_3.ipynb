{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tutorial_3","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO4jVThaqvYYJk4Bf5Naxmu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Tutorial 3\n","The model we developed in the previous tutorial classified MNIST successfully but was rather slow. Like ANNs, to maximise performance when simulating small SNNs like this on a GPU, we need to simulate multiple copies of the model at once and run them on **batches** of input images.\n","In this tutorial we will modify our model to do just that as well as off-loading further computation to the GPU to improve performance.\n","\n","## Install PyGeNN wheel from Google Drive\n","Download wheel file"],"metadata":{"id":"lGa0_oLb61zz"}},{"cell_type":"code","source":["!gdown 1_FGztpOraIhcPCIVQsi1ksKcA1jIwO9K\n"],"metadata":{"id":"t2ihZLXh5VD-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651526581296,"user_tz":-60,"elapsed":16616,"user":{"displayName":"Jamie Knight","userId":"17931559686369144807"}},"outputId":"c658db69-7972-4836-bf28-2292a6a2c1de"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1_FGztpOraIhcPCIVQsi1ksKcA1jIwO9K\n","To: /content/pygenn-4.7.1-cp37-cp37m-linux_x86_64.whl\n","\r  0% 0.00/13.8M [00:00<?, ?B/s]\r100% 13.8M/13.8M [00:00<00:00, 191MB/s]\n"]}]},{"cell_type":"markdown","source":["and then install PyGeNN from wheel file"],"metadata":{"id":"4oxLk_xy67Pd"}},{"cell_type":"code","source":["!pip install pygenn-4.7.1-cp37-cp37m-linux_x86_64.whl"],"metadata":{"id":"v7Hg9SPK5bZO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651526583983,"user_tz":-60,"elapsed":2697,"user":{"displayName":"Jamie Knight","userId":"17931559686369144807"}},"outputId":"942c7444-e915-4cfa-9e0b-59d2574de1ea"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing ./pygenn-4.7.1-cp37-cp37m-linux_x86_64.whl\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from pygenn==4.7.1) (5.4.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pygenn==4.7.1) (1.15.0)\n","Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from pygenn==4.7.1) (4.11.3)\n","Requirement already satisfied: deprecated in /usr/local/lib/python3.7/dist-packages (from pygenn==4.7.1) (1.2.13)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from pygenn==4.7.1) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->pygenn==4.7.1) (4.2.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->pygenn==4.7.1) (3.8.0)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated->pygenn==4.7.1) (1.14.0)\n","pygenn is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n"]}]},{"cell_type":"markdown","source":["Set environment variable to allow GeNN to find CUDA"],"metadata":{"id":"cAm5bzGvAb17"}},{"cell_type":"code","source":["%env CUDA_PATH=/usr/local/cuda"],"metadata":{"id":"cIzSgI5Q8Wvq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651526583984,"user_tz":-60,"elapsed":23,"user":{"displayName":"Jamie Knight","userId":"17931559686369144807"}},"outputId":"19f9d9b4-22aa-4ede-810f-127b76ff7c8c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["env: CUDA_PATH=/usr/local/cuda\n"]}]},{"cell_type":"markdown","source":["## Download pre-trained weights and MNIST test data"],"metadata":{"id":"8tqbF5GldF0o"}},{"cell_type":"code","source":["!gdown 1cmNL8W0QZZtn3dPHiOQnVjGAYTk6Rhpc\n","!gdown 131lCXLEH6aTXnBZ9Nh4eJLSy5DQ6LKSF\n","!gdown 14nSMTTlFebhqkudWVpuWnNFFEQx_7lFg\n","!gdown 1KSLTNx--oNoV1lEGPmo0FQbUlgsmaBKS"],"metadata":{"id":"N-2PV7LcdFg_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651526596025,"user_tz":-60,"elapsed":12054,"user":{"displayName":"Jamie Knight","userId":"17931559686369144807"}},"outputId":"b21e864d-a7cc-4654-f894-8142814301e5"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1cmNL8W0QZZtn3dPHiOQnVjGAYTk6Rhpc\n","To: /content/weights_0_1.npy\n","100% 402k/402k [00:00<00:00, 66.0MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=131lCXLEH6aTXnBZ9Nh4eJLSy5DQ6LKSF\n","To: /content/weights_1_2.npy\n","100% 5.25k/5.25k [00:00<00:00, 7.49MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=14nSMTTlFebhqkudWVpuWnNFFEQx_7lFg\n","To: /content/testing_images.npy\n","100% 7.84M/7.84M [00:00<00:00, 209MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1KSLTNx--oNoV1lEGPmo0FQbUlgsmaBKS\n","To: /content/testing_labels.npy\n","100% 10.1k/10.1k [00:00<00:00, 13.2MB/s]\n"]}]},{"cell_type":"markdown","source":["## Build model\n","Import standard module and PyGeNN functionality as before and configure simulation parameters"],"metadata":{"id":"jBVpqi2k5mNb"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from pygenn.genn_model import (create_custom_neuron_class,\n","                               create_custom_current_source_class,\n","                               create_custom_custom_update_class,\n","                               create_var_ref,\n","                               GeNNModel)\n","from time import perf_counter\n","from tqdm import tqdm\n","\n","TIMESTEP = 1.0\n","PRESENT_TIMESTEPS = 100\n","INPUT_CURRENT_SCALE = 1.0 / 100.0"],"metadata":{"id":"agqWFZjickfU","executionInfo":{"status":"ok","timestamp":1651526596025,"user_tz":-60,"elapsed":14,"user":{"displayName":"Jamie Knight","userId":"17931559686369144807"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["As we're going to use it in a few places, we add an additional simulation parameter to define the batch size."],"metadata":{"id":"OTkuiEAx5qMG"}},{"cell_type":"code","source":["BATCH_SIZE = 128"],"metadata":{"id":"ejMfqnhAkrye","executionInfo":{"status":"ok","timestamp":1651526596026,"user_tz":-60,"elapsed":13,"user":{"displayName":"Jamie Knight","userId":"17931559686369144807"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["Define the custom neuron and synapse models in exactly the same way as before"],"metadata":{"id":"fojA3yl_6KU9"}},{"cell_type":"code","source":["# Very simple integrate-and-fire neuron model\n","if_model = create_custom_neuron_class(\n","    \"if_model\",\n","    param_names=[\"Vthr\"],\n","    var_name_types=[(\"V\", \"scalar\"), (\"SpikeCount\", \"unsigned int\")],\n","    sim_code=\"$(V) += $(Isyn) * DT;\",\n","    reset_code=\"\"\"\n","    $(V) = 0.0;\n","    $(SpikeCount)++;\n","    \"\"\",\n","    threshold_condition_code=\"$(V) >= $(Vthr)\")\n","\n","cs_model = create_custom_current_source_class(\n","    \"cs_model\",\n","    var_name_types=[(\"magnitude\", \"scalar\")],\n","    injection_code=\"$(injectCurrent, $(magnitude));\")\n"],"metadata":{"id":"-7lzXzmQcgbt","executionInfo":{"status":"ok","timestamp":1651526596026,"user_tz":-60,"elapsed":11,"user":{"displayName":"Jamie Knight","userId":"17931559686369144807"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["As we increase the batch size of our model, the cost of resetting the spike counts and membrane voltages will increase. To counteract this, we can offload tasks like this to the GPU using a *custom update* model. These are defined using very similar syntax to neuron and synapse models but have one additional feature - variable references. These allow custom updates to be *attached* to existing neuron or synapse populations to modify their variables outside of the standard neuron and synapse updates."],"metadata":{"id":"93YuiQG7qzG3"}},{"cell_type":"code","source":["reset_model = create_custom_custom_update_class(\n","    \"reset\",\n","    param_names=[],\n","    var_name_types=[],\n","    var_refs=[(\"V\", \"scalar\"), (\"SpikeCount\", \"unsigned int\")],\n","    update_code=\"\"\"\n","    $(V) = 0.0;\n","    $(SpikeCount) = 0;\n","    \"\"\")"],"metadata":{"id":"I8KZoiK1nQlK","executionInfo":{"status":"ok","timestamp":1651526596027,"user_tz":-60,"elapsed":12,"user":{"displayName":"Jamie Knight","userId":"17931559686369144807"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["Create a new model in exactly the same way as before"],"metadata":{"id":"kDWkDTCWqwt3"}},{"cell_type":"code","source":["model = GeNNModel(\"float\", \"tutorial_3\")\n","model.dT = TIMESTEP"],"metadata":{"id":"BSSdg6ckl6im","executionInfo":{"status":"ok","timestamp":1651526596027,"user_tz":-60,"elapsed":11,"user":{"displayName":"Jamie Knight","userId":"17931559686369144807"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["Set the model batch size"],"metadata":{"id":"njWcYaZk5w7G"}},{"cell_type":"code","source":["model.batch_size = BATCH_SIZE"],"metadata":{"id":"iOyB3Z6qkVBM","executionInfo":{"status":"ok","timestamp":1651526596028,"user_tz":-60,"elapsed":12,"user":{"displayName":"Jamie Knight","userId":"17931559686369144807"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Build model, load weights and create neuron, synapse and current source populations as before"],"metadata":{"id":"enyL8xum-OpC"}},{"cell_type":"code","source":["# Load weights\n","weights_0_1 = np.load(\"weights_0_1.npy\")\n","weights_1_2 = np.load(\"weights_1_2.npy\")\n","\n","if_params = {\"Vthr\": 5.0}\n","if_init = {\"V\": 0.0, \"SpikeCount\":0}\n","neurons = [model.add_neuron_population(\"neuron0\", weights_0_1.shape[0],\n","                                       if_model, if_params, if_init),\n","           model.add_neuron_population(\"neuron1\", weights_0_1.shape[1],\n","                                       if_model, if_params, if_init),\n","           model.add_neuron_population(\"neuron2\", weights_1_2.shape[1],\n","                                       if_model, if_params, if_init)]\n","model.add_synapse_population(\n","        \"synapse_0_1\", \"DENSE_INDIVIDUALG\", 0,\n","        neurons[0], neurons[1],\n","        \"StaticPulse\", {}, {\"g\": weights_0_1.flatten()}, {}, {},\n","        \"DeltaCurr\", {}, {})\n","model.add_synapse_population(\n","        \"synapse_1_2\", \"DENSE_INDIVIDUALG\", 0,\n","        neurons[1], neurons[2],\n","        \"StaticPulse\", {}, {\"g\": weights_1_2.flatten()}, {}, {},\n","        \"DeltaCurr\", {}, {});\n","\n","current_input = model.add_current_source(\"current_input\", cs_model,\n","                                         neurons[0], {}, {\"magnitude\": 0.0})"],"metadata":{"id":"Sx1VOU5udixG","executionInfo":{"status":"ok","timestamp":1651526596028,"user_tz":-60,"elapsed":11,"user":{"displayName":"Jamie Knight","userId":"17931559686369144807"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"3S_ZASOdrnj3"}},{"cell_type":"code","source":["for n in neurons:\n","    reset_var_refs = {\"V\": create_var_ref(n, \"V\"),\n","                      \"SpikeCount\": create_var_ref(n, \"SpikeCount\")}\n","    model.add_custom_update(f\"{n.name}_optimizer\", \"Reset\", reset_model,\n","                            {}, {}, reset_var_refs)"],"metadata":{"id":"7PW3c8ibpx9x","executionInfo":{"status":"ok","timestamp":1651526621888,"user_tz":-60,"elapsed":439,"user":{"displayName":"Jamie Knight","userId":"17931559686369144807"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"vv-XOushroKw"}},{"cell_type":"code","source":["# Build and load our model\n","model.build()\n","model.load()\n","\n","testing_images = np.load(\"testing_images.npy\")\n","testing_labels = np.load(\"testing_labels.npy\")\n","\n","assert testing_images.shape[1] == weights_0_1.shape[0]\n","assert np.max(testing_labels) == (weights_1_2.shape[1] - 1)"],"metadata":{"id":"muUbvSHOooev","executionInfo":{"status":"ok","timestamp":1651526641183,"user_tz":-60,"elapsed":16346,"user":{"displayName":"Jamie Knight","userId":"17931559686369144807"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["First of all, we determine where to split our test data to achieve our batch size and then use `np.split` to perform the splitting operation (the last batch will contain < `BATCH_SIZE` stimuli as 128 does not divide 10000 evenly)"],"metadata":{"id":"awF6vfLX-TVM"}},{"cell_type":"code","source":["batch_splits = range(BATCH_SIZE, testing_images.shape[0] + 1, BATCH_SIZE)\n","\n","testing_image_batches = np.split(testing_images, batch_splits, axis=0)\n","testing_label_batches = np.split(testing_labels, batch_splits, axis=0)"],"metadata":{"id":"BB0kXBmQkwCX","executionInfo":{"status":"ok","timestamp":1651526668092,"user_tz":-60,"elapsed":396,"user":{"displayName":"Jamie Knight","userId":"17931559686369144807"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## Simulate model\n","Our batched simulation loop looks very similar to the loop we defined in the previous tutorial however:\n","*   We now loop over *batches* of images and labels rather than individual ones\n","*   When we copy images into the input current view, we only copy as many images as are present in this batch to handle the remainder in the final batch\n","*   We specify an axis for `np.argmax` so that we get the neuron with the largest spike count in each batch\n","\n"],"metadata":{"id":"pd4BBHjtur5E"}},{"cell_type":"code","source":["current_input_magnitude = current_input.vars[\"magnitude\"].view\n","output_spike_count = neurons[-1].vars[\"SpikeCount\"].view\n","neuron_voltages = [n.vars[\"V\"].view for n in neurons]\n","\n","# Simulate\n","num_correct = 0\n","start_time = perf_counter()\n","for img, lab in tqdm(zip(testing_image_batches, testing_label_batches)):\n","    current_input_magnitude[:img.shape[0],:] = img * INPUT_CURRENT_SCALE\n","    current_input.push_var_to_device(\"magnitude\")\n","\n","    # Run reset custom update\n","    model.custom_update(\"Reset\")\n","\n","    for t in range(PRESENT_TIMESTEPS):\n","        model.step_time()\n","\n","    # Download spike count from last layer\n","    neurons[-1].pull_var_from_device(\"SpikeCount\")\n","\n","    # Find which neuron spiked most in each batch to get prediction\n","    predicted_lab = np.argmax(output_spike_count, axis=1)\n","\n","    # Add number of  \n","    num_correct += np.sum(predicted_lab[:lab.shape[0]] == lab)\n","\n","end_time = perf_counter()\n","print(f\"\\nAccuracy {((num_correct / float(testing_images.shape[0])) * 100.0)}%%\")\n","print(f\"Time {end_time - start_time} seconds\")\n"],"metadata":{"id":"4qSoinT4etKq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651526675190,"user_tz":-60,"elapsed":1024,"user":{"displayName":"Jamie Knight","userId":"17931559686369144807"}},"outputId":"824d0f81-66ec-4c54-b742-cc6eae6e2fc4"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["79it [00:00, 104.96it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Accuracy 97.54%%\n","Time 0.7618121939999583 seconds\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["And...we get a speed up of over 30x compared to the previous tutorial"],"metadata":{"id":"y34o04ucAUjJ"}}]}