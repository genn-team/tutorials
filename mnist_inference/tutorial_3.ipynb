{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGa0_oLb61zz"
      },
      "source": [
        "# Tutorial 3\n",
        "The model we developed in the previous tutorial classified MNIST successfully but was rather slow. Like ANNs, to maximise performance when simulating small SNNs like this on a GPU, we need to simulate multiple copies of the model at once and run them on **batches** of input images.\n",
        "In this tutorial we will modify our model to do just that as well as off-loading further computation to the GPU to improve performance.\n",
        "\n",
        "## Install PyGeNN wheel from Google Drive\n",
        "Download wheel file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2ihZLXh5VD-",
        "outputId": "63d27e99-65eb-4912-b9a0-3d31c5696fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fllqUtL_1_tyGzjNHSR-9i5fXFI9jqAi\n",
            "To: /content/pygenn-4.8.1-cp310-cp310-linux_x86_64.whl\n",
            "100% 22.3M/22.3M [00:00<00:00, 73.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1fllqUtL_1_tyGzjNHSR-9i5fXFI9jqAi "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oxLk_xy67Pd"
      },
      "source": [
        "and then install PyGeNN from wheel file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7Hg9SPK5bZO",
        "outputId": "6afb820d-e905-447b-c2ed-0c0a8a541ba2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing ./pygenn-4.8.1-cp310-cp310-linux_x86_64.whl\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from pygenn==4.8.1) (5.9.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pygenn==4.8.1) (1.16.0)\n",
            "Collecting deprecated\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pygenn==4.8.1) (1.22.4)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->pygenn==4.8.1) (1.14.1)\n",
            "Installing collected packages: deprecated, pygenn\n",
            "Successfully installed deprecated-1.2.13 pygenn-4.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pygenn-4.8.1-cp310-cp310-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAm5bzGvAb17"
      },
      "source": [
        "Set environment variable to allow GeNN to find CUDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIzSgI5Q8Wvq",
        "outputId": "a6df540c-de4d-4a7c-f1e8-caf4988b9f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_PATH=/usr/local/cuda\n"
          ]
        }
      ],
      "source": [
        "%env CUDA_PATH=/usr/local/cuda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tqbF5GldF0o"
      },
      "source": [
        "## Download pre-trained weights and MNIST test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-2PV7LcdFg_",
        "outputId": "b577a1f0-9624-44c4-fa62-93283c0849b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cmNL8W0QZZtn3dPHiOQnVjGAYTk6Rhpc\n",
            "To: /content/weights_0_1.npy\n",
            "100% 402k/402k [00:00<00:00, 48.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=131lCXLEH6aTXnBZ9Nh4eJLSy5DQ6LKSF\n",
            "To: /content/weights_1_2.npy\n",
            "100% 5.25k/5.25k [00:00<00:00, 22.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1cmNL8W0QZZtn3dPHiOQnVjGAYTk6Rhpc\n",
        "!gdown 131lCXLEH6aTXnBZ9Nh4eJLSy5DQ6LKSF"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install MNIST package"
      ],
      "metadata": {
        "id": "KVRtXVzIg07T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mnist"
      ],
      "metadata": {
        "id": "AikBc4sfg1b-",
        "outputId": "5fc87850-52e1-4bbe-d81a-d6b909b6dde5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mnist\n",
            "  Downloading mnist-0.2.2-py2.py3-none-any.whl (3.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mnist) (1.22.4)\n",
            "Installing collected packages: mnist\n",
            "Successfully installed mnist-0.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBVpqi2k5mNb"
      },
      "source": [
        "## Build model\n",
        "Import standard module and PyGeNN functionality as before and configure simulation parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "agqWFZjickfU"
      },
      "outputs": [],
      "source": [
        "import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pygenn.genn_model import (create_custom_neuron_class,\n",
        "                               create_custom_current_source_class,\n",
        "                               create_custom_custom_update_class,\n",
        "                               create_var_ref,\n",
        "                               GeNNModel)\n",
        "from time import perf_counter\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "TIMESTEP = 1.0\n",
        "PRESENT_TIMESTEPS = 100\n",
        "INPUT_CURRENT_SCALE = 1.0 / 100.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTkuiEAx5qMG"
      },
      "source": [
        "As we're going to use it in a few places, we add an additional simulation parameter to define the batch size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ejMfqnhAkrye"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fojA3yl_6KU9"
      },
      "source": [
        "Define the custom neuron and synapse models in exactly the same way as before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-7lzXzmQcgbt"
      },
      "outputs": [],
      "source": [
        "# Very simple integrate-and-fire neuron model\n",
        "if_model = create_custom_neuron_class(\n",
        "    \"if_model\",\n",
        "    param_names=[\"Vthr\"],\n",
        "    var_name_types=[(\"V\", \"scalar\"), (\"SpikeCount\", \"unsigned int\")],\n",
        "    sim_code=\"$(V) += $(Isyn) * DT;\",\n",
        "    reset_code=\"\"\"\n",
        "    $(V) = 0.0;\n",
        "    $(SpikeCount)++;\n",
        "    \"\"\",\n",
        "    threshold_condition_code=\"$(V) >= $(Vthr)\")\n",
        "\n",
        "cs_model = create_custom_current_source_class(\n",
        "    \"cs_model\",\n",
        "    var_name_types=[(\"magnitude\", \"scalar\")],\n",
        "    injection_code=\"$(injectCurrent, $(magnitude));\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93YuiQG7qzG3"
      },
      "source": [
        "As we increase the batch size of our model, the cost of resetting the spike counts and membrane voltages will increase. To counteract this, we can offload tasks like this to the GPU using a *custom update* model. These are defined using very similar syntax to neuron and synapse models but have one additional feature - variable references. These allow custom updates to be *attached* to existing neuron or synapse populations to modify their variables outside of the standard neuron and synapse updates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "I8KZoiK1nQlK"
      },
      "outputs": [],
      "source": [
        "reset_model = create_custom_custom_update_class(\n",
        "    \"reset\",\n",
        "    param_names=[],\n",
        "    var_name_types=[],\n",
        "    var_refs=[(\"V\", \"scalar\"), (\"SpikeCount\", \"unsigned int\")],\n",
        "    update_code=\"\"\"\n",
        "    $(V) = 0.0;\n",
        "    $(SpikeCount) = 0;\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDWkDTCWqwt3"
      },
      "source": [
        "Create a new model in exactly the same way as before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BSSdg6ckl6im"
      },
      "outputs": [],
      "source": [
        "model = GeNNModel(\"float\", \"tutorial_3\")\n",
        "model.dT = TIMESTEP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njWcYaZk5w7G"
      },
      "source": [
        "Set the model batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iOyB3Z6qkVBM"
      },
      "outputs": [],
      "source": [
        "model.batch_size = BATCH_SIZE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enyL8xum-OpC"
      },
      "source": [
        "Build model, load weights and create neuron, synapse and current source populations as before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Sx1VOU5udixG"
      },
      "outputs": [],
      "source": [
        "# Load weights\n",
        "weights_0_1 = np.load(\"weights_0_1.npy\")\n",
        "weights_1_2 = np.load(\"weights_1_2.npy\")\n",
        "\n",
        "if_params = {\"Vthr\": 5.0}\n",
        "if_init = {\"V\": 0.0, \"SpikeCount\":0}\n",
        "neurons = [model.add_neuron_population(\"neuron0\", weights_0_1.shape[0],\n",
        "                                       if_model, if_params, if_init),\n",
        "           model.add_neuron_population(\"neuron1\", weights_0_1.shape[1],\n",
        "                                       if_model, if_params, if_init),\n",
        "           model.add_neuron_population(\"neuron2\", weights_1_2.shape[1],\n",
        "                                       if_model, if_params, if_init)]\n",
        "model.add_synapse_population(\n",
        "        \"synapse_0_1\", \"DENSE_INDIVIDUALG\", 0,\n",
        "        neurons[0], neurons[1],\n",
        "        \"StaticPulse\", {}, {\"g\": weights_0_1.flatten()}, {}, {},\n",
        "        \"DeltaCurr\", {}, {})\n",
        "model.add_synapse_population(\n",
        "        \"synapse_1_2\", \"DENSE_INDIVIDUALG\", 0,\n",
        "        neurons[1], neurons[2],\n",
        "        \"StaticPulse\", {}, {\"g\": weights_1_2.flatten()}, {}, {},\n",
        "        \"DeltaCurr\", {}, {});\n",
        "\n",
        "current_input = model.add_current_source(\"current_input\", cs_model,\n",
        "                                         neurons[0], {}, {\"magnitude\": 0.0})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3S_ZASOdrnj3"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7PW3c8ibpx9x"
      },
      "outputs": [],
      "source": [
        "for n in neurons:\n",
        "    reset_var_refs = {\"V\": create_var_ref(n, \"V\"),\n",
        "                      \"SpikeCount\": create_var_ref(n, \"SpikeCount\")}\n",
        "    model.add_custom_update(f\"{n.name}_optimizer\", \"Reset\", reset_model,\n",
        "                            {}, {}, reset_var_refs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv-XOushroKw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "muUbvSHOooev"
      },
      "outputs": [],
      "source": [
        "# Build and load our model\n",
        "model.build()\n",
        "model.load()\n",
        "\n",
        "testing_images = mnist.test_images()\n",
        "testing_labels = mnist.test_labels()\n",
        "\n",
        "testing_images = np.reshape(testing_images, (testing_images.shape[0], -1))\n",
        "assert testing_images.shape[1] == weights_0_1.shape[0]\n",
        "assert np.max(testing_labels) == (weights_1_2.shape[1] - 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awF6vfLX-TVM"
      },
      "source": [
        "First of all, we determine where to split our test data to achieve our batch size and then use `np.split` to perform the splitting operation (the last batch will contain < `BATCH_SIZE` stimuli as 128 does not divide 10000 evenly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BB0kXBmQkwCX"
      },
      "outputs": [],
      "source": [
        "batch_splits = range(BATCH_SIZE, testing_images.shape[0] + 1, BATCH_SIZE)\n",
        "\n",
        "testing_image_batches = np.split(testing_images, batch_splits, axis=0)\n",
        "testing_label_batches = np.split(testing_labels, batch_splits, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pd4BBHjtur5E"
      },
      "source": [
        "## Simulate model\n",
        "Our batched simulation loop looks very similar to the loop we defined in the previous tutorial however:\n",
        "*   We now loop over *batches* of images and labels rather than individual ones\n",
        "*   When we copy images into the input current view, we only copy as many images as are present in this batch to handle the remainder in the final batch\n",
        "*   We specify an axis for `np.argmax` so that we get the neuron with the largest spike count in each batch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "2e0663a22e9b4623afaccb70ac3238f1",
            "c6cd54c02dd24187b2f482b70107e2f9",
            "8f03b0ecacc4485db93d1c96dc120cff",
            "6008a03e5f8244538fe55f4b1978c2b8",
            "3ba12d4f5a1846888d5bb462c8def69f",
            "fb962ca3fc704257b07671837c26a487",
            "2d445347b4fa473481bf84ca0e06d2aa",
            "8ca53f9d93ce4c27b228e1f4b7345d3e",
            "868454338aef4bbfb1d5ffba9c800c70",
            "66d5ec28b0e04fd1b7c61d193ada5a5f",
            "1e4d5b55914248658ec46dcc8d53fbb6"
          ]
        },
        "id": "4qSoinT4etKq",
        "outputId": "ac1c6de0-bbe8-460b-acf3-93528b3d0e0a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/79 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e0663a22e9b4623afaccb70ac3238f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy 97.53%%\n",
            "Time 0.29277160499998445 seconds\n"
          ]
        }
      ],
      "source": [
        "current_input_magnitude = current_input.vars[\"magnitude\"].view\n",
        "output_spike_count = neurons[-1].vars[\"SpikeCount\"].view\n",
        "neuron_voltages = [n.vars[\"V\"].view for n in neurons]\n",
        "\n",
        "# Simulate\n",
        "num_correct = 0\n",
        "start_time = perf_counter()\n",
        "for img, lab in tqdm(zip(testing_image_batches, testing_label_batches), \n",
        "                     total=len(testing_image_batches)):\n",
        "    current_input_magnitude[:img.shape[0],:] = img * INPUT_CURRENT_SCALE\n",
        "    current_input.push_var_to_device(\"magnitude\")\n",
        "\n",
        "    # Run reset custom update\n",
        "    model.custom_update(\"Reset\")\n",
        "\n",
        "    for t in range(PRESENT_TIMESTEPS):\n",
        "        model.step_time()\n",
        "\n",
        "    # Download spike count from last layer\n",
        "    neurons[-1].pull_var_from_device(\"SpikeCount\")\n",
        "\n",
        "    # Find which neuron spiked most in each batch to get prediction\n",
        "    predicted_lab = np.argmax(output_spike_count, axis=1)\n",
        "\n",
        "    # Add number of  \n",
        "    num_correct += np.sum(predicted_lab[:lab.shape[0]] == lab)\n",
        "\n",
        "end_time = perf_counter()\n",
        "print(f\"\\nAccuracy {((num_correct / float(testing_images.shape[0])) * 100.0)}%%\")\n",
        "print(f\"Time {end_time - start_time} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y34o04ucAUjJ"
      },
      "source": [
        "And...we get a speed up of over 30x compared to the previous tutorial"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tutorial_3",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2e0663a22e9b4623afaccb70ac3238f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6cd54c02dd24187b2f482b70107e2f9",
              "IPY_MODEL_8f03b0ecacc4485db93d1c96dc120cff",
              "IPY_MODEL_6008a03e5f8244538fe55f4b1978c2b8"
            ],
            "layout": "IPY_MODEL_3ba12d4f5a1846888d5bb462c8def69f"
          }
        },
        "c6cd54c02dd24187b2f482b70107e2f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb962ca3fc704257b07671837c26a487",
            "placeholder": "​",
            "style": "IPY_MODEL_2d445347b4fa473481bf84ca0e06d2aa",
            "value": "100%"
          }
        },
        "8f03b0ecacc4485db93d1c96dc120cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ca53f9d93ce4c27b228e1f4b7345d3e",
            "max": 79,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_868454338aef4bbfb1d5ffba9c800c70",
            "value": 79
          }
        },
        "6008a03e5f8244538fe55f4b1978c2b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66d5ec28b0e04fd1b7c61d193ada5a5f",
            "placeholder": "​",
            "style": "IPY_MODEL_1e4d5b55914248658ec46dcc8d53fbb6",
            "value": " 79/79 [00:00&lt;00:00, 264.11it/s]"
          }
        },
        "3ba12d4f5a1846888d5bb462c8def69f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb962ca3fc704257b07671837c26a487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d445347b4fa473481bf84ca0e06d2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ca53f9d93ce4c27b228e1f4b7345d3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "868454338aef4bbfb1d5ffba9c800c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66d5ec28b0e04fd1b7c61d193ada5a5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e4d5b55914248658ec46dcc8d53fbb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}